package stubs;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

/* 
 * This class defines the reduce function for the MapReduce job.
 * It processes intermediate key-value pairs generated by the mapper.
 */
public class SumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

  /*
   * The reduce method is called for each key received from the mappers.
   * It takes a key of type Text (the word) and an iterable of values of type IntWritable (counts).
   */
  @Override
  public void reduce(Text key, Iterable<IntWritable> values, Context context)
      throws IOException, InterruptedException {
    int wordCount = 0; // Initialize a counter for the word.

    // I iterate over the values associated with the key and sum them up.
    for (IntWritable value : values) {
      wordCount += value.get(); // Add the count from each mapper.
    }

    // I emit the word and its total count as the output of the reducer.
    context.write(key, new IntWritable(wordCount));
  }
}
